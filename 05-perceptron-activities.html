<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <meta content="width=device-width, initial-scale=1.0" name="viewport">

  <title> e-Portfolio</title>
  <meta content="" name="description">
  <meta content="" name="keywords">

  <!-- Favicons -->
  <link href="assets/img/favicon.png" rel="icon">
  <link href="assets/img/apple-touch-icon.png" rel="apple-touch-icon">

  <!-- Vendor CSS Files -->
  <link href="assets/vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">
  <link href="assets/vendor/bootstrap-icons/bootstrap-icons.css" rel="stylesheet">
  <link href="assets/vendor/glightbox/css/glightbox.min.css" rel="stylesheet">
  <link href="assets/vendor/swiper/swiper-bundle.min.css" rel="stylesheet">

  <!-- Template Main CSS File -->
  <link href="assets/css/style.css" rel="stylesheet">

  <!-- =======================================================
  * Template Name: DevFolio
  * Updated: Sep 18 2023 with Bootstrap v5.3.2
  * Template URL: https://bootstrapmade.com/devfolio-bootstrap-portfolio-html-template/
  * Author: BootstrapMade.com
  * License: https://bootstrapmade.com/license/
  ======================================================== -->
</head>

<body>

  <!-- ======= Header ======= -->
  <header id="header" class="fixed-top" style="background-color: black;">
    <div class="container d-flex align-items-center justify-content-between">

      <h1 class="logo"><a href="index.html">Danilo De Sousa</a></h1>
      <!-- Uncomment below if you prefer to use an image logo -->
      <!-- <a href="index.html" class="logo"><img src="assets/img/logo.png" alt="" class="img-fluid"></a>-->

      <nav id="navbar" class="navbar">
        <ul>
          <li><a class="nav-link scrollto active" href="./index.html">Home</a></li>

        </ul>
        <i class="bi bi-list mobile-nav-toggle"></i>
      </nav><!-- .navbar -->

    </div>
  </header><!-- End Header -->

  <div class="hero hero-single route bg-image" style="background-image: url(assets/img/overlay-bg.jpg)">
    <div class="overlay-mf"></div>
    <div class="hero-content display-table">
      <div class="table-cell">
        <div class="container">
          <h2 class="hero-title mb-4">Activation Functions</h2>

        </div>
      </div>
    </div>
  </div>

  <main id="main">

    <!-- ======= Portfolio Details Section ======= -->
    <section id="portfolio-details" class="portfolio-details">
      <div class="container"> 
        <div> 
          <div class="col-lg-12"> 
            <div class="portfolio-description"> 
              <p>Activation functions in neural networks are crucial components that introduce nonlinearity into the
                network, allowing it to learn complex patterns and relationships in data. They are applied to the output
                of each neuron in a neural network, transforming the input signal into the neuron's output.</p>
              <p>Here are some common activation functions:</p>
              <ul>
                <li><strong>Sigmoid Function (Logistic)</strong>: Smooth, continuous function that compresses the input
                  into a range between 0 and 1. It is useful in the output layer of binary classification tasks, but
                  presents problems of vanishing gradients for deep networks.</li>
                <li>

                  <strong>Hyperbolic Tangent Function (tanh)</strong>: Similar to the sigmoid function, but with an
                  output range between -1 and 1, which centers the output around zero. It suffers from the evanescent
                  gradient problem similar to the sigmoid function.
                </li>
                <li>
                  <strong>Rectified Linear Unit (ReLU)</strong>: Simple and computationally efficient. It replaces all
                  negative entries with zero, leaving positive entries unchanged. ReLU has become the default activation
                  function for many deep learning applications.
                </li>
                <li>
                  <strong>Leaky ReLU</strong>: A variation of ReLU that allows a small, non-zero gradient when the input
                  is negative, solving the problem of "dying ReLU" where neurons can get stuck during training if they
                  always output zero.
                </li>
                <li>
                  <strong>Parametric ReLU (PReLU)</strong>: Similar to Leaky ReLU, but the bias for negative values is
                  learned during training.
                </li>
                <li>
                  <strong>Exponential Linear Unit (ELU)</strong>: Similar to ReLU, but allows negative values with
                  exponential decay.
                </li>
                <li>
                  <strong>Softmax function</strong>: Typically used in the output layer for multi-class classification
                  tasks. It normalizes the output into a multi-class probability distribution.
                </li> 
              </ul> 
              <p>
                Each activation function has its advantages and disadvantages, and the choice often depends on the
                specific problem, the network architecture, and empirical testing to determine which one performs best
                for a specific task.

              </p>  
              <br></br>
              <p>

                <b> References</b>
              </p>
              <p>
                Sharma, S., Sharma, S. & Athaiya, A. (2020) Activation Funcions in Neural Networks. <i>International Journal of Engineering Applied Sciences and Technology</i> 4(12):310-316. Available from: https://www.ijeast.com/papers/310-316,Tesma412,IJEAST.pdf [Accessed 20 March 2024]
              </p>


            </div>
          </div>

        </div>

      </div>
    </section><!-- End Portfolio Details Section -->

  </main><!-- End #main -->

  <!-- ======= Footer ======= -->
  <footer>
    <div class="container">
      <div class="row">
        <div class="col-sm-12">
          <div class="copyright-box">
            <p class="copyright">&copy; Copyright <strong>DevFolio</strong>. All Rights Reserved</p>
            <div class="credits">
              <!--
              All the links in the footer should remain intact.
              You can delete the links only if you purchased the pro version.
              Licensing information: https://bootstrapmade.com/license/
              Purchase the pro version with working PHP/AJAX contact form: https://bootstrapmade.com/buy/?theme=DevFolio
            -->
              Designed by <a href="https://bootstrapmade.com/">BootstrapMade</a>
            </div>
          </div>
        </div>
      </div>
    </div>
  </footer><!-- End  Footer -->

  <div id="preloader"></div>
  <a href="#" class="back-to-top d-flex align-items-center justify-content-center"><i
      class="bi bi-arrow-up-short"></i></a>

  <!-- Vendor JS Files -->
  <script src="assets/vendor/purecounter/purecounter_vanilla.js"></script>
  <script src="assets/vendor/bootstrap/js/bootstrap.bundle.min.js"></script>
  <script src="assets/vendor/glightbox/js/glightbox.min.js"></script>
  <script src="assets/vendor/swiper/swiper-bundle.min.js"></script>
  <script src="assets/vendor/typed.js/typed.umd.js"></script>
  <script src="assets/vendor/php-email-form/validate.js"></script>

  <!-- Template Main JS File -->
  <script src="assets/js/main.js"></script>

</body>

</html>